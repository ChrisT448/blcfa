---
title: Notes on 2019 R conference
author: Lijin Zhang
date: May 24, 2019
output: 
  rmdformats::readthedown:
    highlight: kate
---
## 用数据诠释实际问题-易丹辉

统计中的数据都是有背景的

数据质量：数据诠释实际问题的基础，如果质量不好，再科学的分析方法都无意义

多种类型数据的综合利用：分类，连续变量的离散化

数据的不平衡：如何处理？  如探究产生不良反应的人群，但是数据中这群人非常少

### 如何用数据说话

#### 1. 数据分布特征展示——描述性分析

	数据的基本分布特征需要心中有数，是跑模型等的基础
	
	数据的描述性分析--数据的分布特征--合理分组
	
		ex,均值标准差，意义在哪？你需要说明什么？更合适的是画分布图并利用所有能够利用的指标，如四分位数等等。核心思想：这个分布告诉了你什么？
		
		用的指标越多，越能看出来数据是否本身有问题，是否有特殊的情况？例如住院一天的情况：追溯：都是来化疗的
		
		很好看的相关强度图..长度粗细表示大小		
		
#### 2. 模型的正确使用

	注意模型运用的条件，可以解释和说明的问题
	
	模型是为了说明实际现象的，模型结果必须要有合理的解释
	
	模型选择--检验--评价--解释
	
	ex. 回归：t检验通过显示这个因素可能重要，但是这个模型合理吗？还需要其它检验
	
#### 3. 多种方法的综合运用可以帮助我们更逼近现象的本质

	大量的偶然中会发现必然
	
	深入分析事物的规律
	
	**补充，函数型数据分析；R包fda, refund**
	
	R包是个傻瓜包，如果对方法没有理解直接调用会有错误，实现时有些程序需要调整


## 数据科学在医疗领域的机遇与挑战--余声

### 常见数据

电子病历，影像组学（目前最火），基因组学（以电子病历做辅助），穿戴设备采集的数据

研究问题：疾病的影响因素，预防和治疗因素，干预治疗决策


## 从模型驱动的集体推断到数据驱动的个体预测 --吴喜之

### 传统数理统计和现代数据科学
	
	1. 数理统计核心；数据驱动的集体推断

	对数据做主观假定（模型驱动为前提）
		
	核心为集体、平均（对象是正态，均值等等）
	
	目标：“显著性”
	
	不追求个体
	

	2. 数据科学：数据驱动的个体预测

	让数据说话（数据驱动为前提）
	
	核心为个体/个性化服务：对于企业服务等尤为重要

### 传统的问题

	只考虑均值可能带来的很大的偏差
	
	由于伟大的中心极限定理，产生了以均值为目标、以正态分布为主要手段的数理统计显著性推断的黄金时代（前计算机时代）
	
	而近日：统计学家反对统计显著性：将要影响与显著性相关的产业链
	
	p值小每一条都值得怀疑：
	
	![](wxz.jph)
	
	此外科学检验只能证伪，不能证实。否则只要样本量够少，都可以证实H0。此外，不仅仅要是大样本才可以检验，还需要正态。
	
### 统计人眼中的统计显著性

	统计显著性没有客观标准，没有精确度的度量。它通过既非科学
	
### 最小二乘线性回归应该数据数据科学中最早应用的预测模型

	但是目前，大部分回归教科书很少谈论预测精度，都在搞参数的显著性。
	
	反对机器学习方法的一个最常用借口是“机器学习是黑匣子”，而且声称“线性回归具有可解释性”
	
	机器学习的可解释性是根据数据的可解释性。而线性回归是根据假定的可解释性。不能靠假定，要靠数据。
	
### 皇帝的新衣——回归模型的可解释性
	
	![](wxz2.jpg)
	
	![](wxz3.jpg)
	
	实际上，多重线性回归中单独某个系数没有可解释性，只有对因变量预测的共同影响，除非自变量矩阵为正交矩阵
	
	统计思维应该就是科学思维！
	
	《50 years of Data Science》
	
### 对数据科学的理解

	1. 统计就是数据科学--过高估计统计

	数据科学的优势

	![](wxz4.jpg)
	
### 数据科学的原则

	可预测性
	
	可计算性
	
	稳定性 
	
### 答疑：机器学习的可解释性。work就可以，也未必是最优解

## 数字时代的乱象与隐忧-张建民

### 数字时代的乱象与隐忧

	数据垄断

	
	
	
	








